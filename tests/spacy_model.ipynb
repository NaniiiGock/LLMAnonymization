{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in ./.venv/lib/python3.12/site-packages (3.8.4)\n",
      "Collecting deepeval\n",
      "  Downloading deepeval-2.3.7-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting ragas\n",
      "  Downloading ragas-0.2.13-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.3.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./.venv/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.venv/lib/python3.12/site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.venv/lib/python3.12/site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.venv/lib/python3.12/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in ./.venv/lib/python3.12/site-packages (from spacy) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./.venv/lib/python3.12/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./.venv/lib/python3.12/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./.venv/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in ./.venv/lib/python3.12/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in ./.venv/lib/python3.12/site-packages (from spacy) (0.15.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./.venv/lib/python3.12/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./.venv/lib/python3.12/site-packages (from spacy) (2.2.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./.venv/lib/python3.12/site-packages (from spacy) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from spacy) (3.1.5)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from spacy) (75.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from spacy) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./.venv/lib/python3.12/site-packages (from spacy) (3.5.0)\n",
      "Collecting pytest (from deepeval)\n",
      "  Downloading pytest-8.3.4-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting tabulate (from deepeval)\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: rich in ./.venv/lib/python3.12/site-packages (from deepeval) (13.9.4)\n",
      "Requirement already satisfied: protobuf in ./.venv/lib/python3.12/site-packages (from deepeval) (5.29.3)\n",
      "Collecting sentry-sdk (from deepeval)\n",
      "  Downloading sentry_sdk-2.21.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pytest-repeat (from deepeval)\n",
      "  Downloading pytest_repeat-0.9.3-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting pytest-xdist (from deepeval)\n",
      "  Downloading pytest_xdist-3.6.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting portalocker (from deepeval)\n",
      "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: langchain in ./.venv/lib/python3.12/site-packages (from deepeval) (0.3.18)\n",
      "Collecting llama-index (from deepeval)\n",
      "  Downloading llama_index-0.12.17-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: langchain-core in ./.venv/lib/python3.12/site-packages (from deepeval) (0.3.34)\n",
      "Requirement already satisfied: langchain_openai in ./.venv/lib/python3.12/site-packages (from deepeval) (0.3.4)\n",
      "Requirement already satisfied: langchain-community in ./.venv/lib/python3.12/site-packages (from deepeval) (0.3.17)\n",
      "Collecting docx2txt~=0.8 (from deepeval)\n",
      "  Using cached docx2txt-0.8.tar.gz (2.8 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting importlib-metadata>=6.0.2 (from deepeval)\n",
      "  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: tenacity<=9.0.0 in ./.venv/lib/python3.12/site-packages (from deepeval) (9.0.0)\n",
      "Collecting opentelemetry-api<2.0.0,>=1.24.0 (from deepeval)\n",
      "  Downloading opentelemetry_api-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-sdk<2.0.0,>=1.24.0 (from deepeval)\n",
      "  Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0 (from deepeval)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting grpcio==1.67.1 (from deepeval)\n",
      "  Downloading grpcio-1.67.1-cp312-cp312-macosx_10_9_universal2.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: nest-asyncio in ./.venv/lib/python3.12/site-packages (from deepeval) (1.6.0)\n",
      "Requirement already satisfied: tiktoken in ./.venv/lib/python3.12/site-packages (from ragas) (0.8.0)\n",
      "Collecting appdirs (from ragas)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: openai>1 in ./.venv/lib/python3.12/site-packages (from ragas) (1.61.1)\n",
      "Collecting diskcache>=5.6.3 (from ragas)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from datasets) (3.17.0)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-19.0.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
      "  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.12/site-packages (from datasets) (3.11.12)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in ./.venv/lib/python3.12/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Collecting zipp>=3.20 (from importlib-metadata>=6.0.2->deepeval)\n",
      "  Using cached zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: language-data>=1.2 in ./.venv/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.12/site-packages (from openai>1->ragas) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.12/site-packages (from openai>1->ragas) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from openai>1->ragas) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from openai>1->ragas) (0.8.2)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from openai>1->ragas) (1.3.1)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api<2.0.0,>=1.24.0->deepeval)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting importlib-metadata>=6.0.2 (from deepeval)\n",
      "  Using cached importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval)\n",
      "  Downloading googleapis_common_protos-1.67.0-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval)\n",
      "  Downloading opentelemetry_proto-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.51b0 (from opentelemetry-sdk<2.0.0,>=1.24.0->deepeval)\n",
      "  Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in ./.venv/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./.venv/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./.venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.12/site-packages (from rich->deepeval) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from rich->deepeval) (2.19.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in ./.venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in ./.venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in ./.venv/lib/python3.12/site-packages (from langchain->deepeval) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in ./.venv/lib/python3.12/site-packages (from langchain->deepeval) (0.3.8)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.12/site-packages (from langchain->deepeval) (2.0.38)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.12/site-packages (from langchain-core->deepeval) (1.33)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./.venv/lib/python3.12/site-packages (from langchain-community->deepeval) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in ./.venv/lib/python3.12/site-packages (from langchain-community->deepeval) (2.7.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from langchain-community->deepeval) (0.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.12/site-packages (from tiktoken->ragas) (2024.11.6)\n",
      "Collecting llama-index-agent-openai<0.5.0,>=0.4.0 (from llama-index->deepeval)\n",
      "  Downloading llama_index_agent_openai-0.4.5-py3-none-any.whl.metadata (727 bytes)\n",
      "Collecting llama-index-cli<0.5.0,>=0.4.0 (from llama-index->deepeval)\n",
      "  Downloading llama_index_cli-0.4.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core<0.13.0,>=0.12.17 (from llama-index->deepeval)\n",
      "  Downloading llama_index_core-0.12.17-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-index-embeddings-openai<0.4.0,>=0.3.0 (from llama-index->deepeval)\n",
      "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index->deepeval)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.6.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting llama-index-llms-openai<0.4.0,>=0.3.0 (from llama-index->deepeval)\n",
      "  Downloading llama_index_llms_openai-0.3.19-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 (from llama-index->deepeval)\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n",
      "Collecting llama-index-program-openai<0.4.0,>=0.3.0 (from llama-index->deepeval)\n",
      "  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.4.0,>=0.3.0 (from llama-index->deepeval)\n",
      "  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
      "Collecting llama-index-readers-file<0.5.0,>=0.4.0 (from llama-index->deepeval)\n",
      "  Downloading llama_index_readers_file-0.4.5-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index->deepeval)\n",
      "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting nltk>3.8.1 (from llama-index->deepeval)\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas->datasets) (2025.1)\n",
      "Collecting iniconfig (from pytest->deepeval)\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pluggy<2,>=1.5 (from pytest->deepeval)\n",
      "  Using cached pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting execnet>=2.1 (from pytest-xdist->deepeval)\n",
      "  Downloading execnet-2.1.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->deepeval) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->deepeval) (0.9.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in ./.venv/lib/python3.12/site-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.24.0->deepeval) (1.17.2)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai>1->ragas) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>1->ragas) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core->deepeval) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain->deepeval) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain->deepeval) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain->deepeval) (0.23.0)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in ./.venv/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.13.0,>=0.12.17->llama-index->deepeval)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.13.0,>=0.12.17->llama-index->deepeval)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: networkx>=3.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index->deepeval) (3.4.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index->deepeval) (10.4.0)\n",
      "Collecting llama-cloud<0.2.0,>=0.1.8 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index->deepeval)\n",
      "  Downloading llama_cloud-0.1.12-py3-none-any.whl.metadata (851 bytes)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.12.3 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->deepeval)\n",
      "  Downloading beautifulsoup4-4.13.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->deepeval)\n",
      "  Downloading pypdf-5.3.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->deepeval)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->deepeval)\n",
      "  Downloading llama_parse-0.6.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->deepeval) (0.1.2)\n",
      "Collecting joblib (from nltk>3.8.1->llama-index->deepeval)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./.venv/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->deepeval) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->deepeval)\n",
      "  Using cached soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.1 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->deepeval)\n",
      "  Downloading llama_cloud_services-0.6.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.17->llama-index->deepeval)\n",
      "  Downloading greenlet-3.1.1-cp312-cp312-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->deepeval) (1.0.0)\n",
      "Downloading deepeval-2.3.7-py3-none-any.whl (559 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m559.1/559.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.67.1-cp312-cp312-macosx_10_9_universal2.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ragas-0.2.13-py3-none-any.whl (178 kB)\n",
      "Downloading datasets-3.3.0-py3-none-any.whl (484 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading opentelemetry_api-1.30.0-py3-none-any.whl (64 kB)\n",
      "Using cached importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.30.0-py3-none-any.whl (55 kB)\n",
      "Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl (118 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl (177 kB)\n",
      "Downloading pyarrow-19.0.0-cp312-cp312-macosx_12_0_arm64.whl (30.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading llama_index-0.12.17-py3-none-any.whl (7.0 kB)\n",
      "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
      "Downloading pytest-8.3.4-py3-none-any.whl (343 kB)\n",
      "Downloading pytest_repeat-0.9.3-py3-none-any.whl (4.2 kB)\n",
      "Downloading pytest_xdist-3.6.1-py3-none-any.whl (46 kB)\n",
      "Downloading sentry_sdk-2.21.0-py2.py3-none-any.whl (324 kB)\n",
      "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading xxhash-3.5.0-cp312-cp312-macosx_11_0_arm64.whl (30 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading execnet-2.1.1-py3-none-any.whl (40 kB)\n",
      "Downloading googleapis_common_protos-1.67.0-py2.py3-none-any.whl (164 kB)\n",
      "Downloading llama_index_agent_openai-0.4.5-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_cli-0.4.0-py3-none-any.whl (27 kB)\n",
      "Downloading llama_index_core-0.12.17-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.6.4-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_llms_openai-0.3.19-py3-none-any.whl (15 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n",
      "Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
      "Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.4.5-py3-none-any.whl (39 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading llama_cloud-0.1.12-py3-none-any.whl (252 kB)\n",
      "Downloading llama_parse-0.6.1-py3-none-any.whl (4.8 kB)\n",
      "Downloading pypdf-5.3.0-py3-none-any.whl (300 kB)\n",
      "Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading greenlet-3.1.1-cp312-cp312-macosx_11_0_universal2.whl (274 kB)\n",
      "Downloading llama_cloud_services-0.6.1-py3-none-any.whl (22 kB)\n",
      "Using cached soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Building wheels for collected packages: docx2txt\n",
      "  Building wheel for docx2txt (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3990 sha256=f1edbc1853ec006ef7fd4e59a1a2f1e9496a4edc95669dad6c4056d05c2c23a0\n",
      "  Stored in directory: /Users/lilianahotsko/Library/Caches/pip/wheels/6f/81/48/001bbc0109c15e18c009eee300022f42d1e070e54f1d00b218\n",
      "Successfully built docx2txt\n",
      "Installing collected packages: striprtf, filetype, docx2txt, dirtyjson, appdirs, zipp, xxhash, tabulate, soupsieve, sentry-sdk, pypdf, pyarrow, portalocker, pluggy, opentelemetry-proto, joblib, iniconfig, grpcio, greenlet, googleapis-common-protos, fsspec, execnet, diskcache, dill, deprecated, pytest, opentelemetry-exporter-otlp-proto-common, nltk, multiprocess, importlib-metadata, beautifulsoup4, pytest-xdist, pytest-repeat, opentelemetry-api, llama-index-core, llama-cloud, opentelemetry-semantic-conventions, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, datasets, opentelemetry-sdk, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, opentelemetry-exporter-otlp-proto-grpc, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, ragas, llama-index, deepeval\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.2.0\n",
      "    Uninstalling fsspec-2025.2.0:\n",
      "      Successfully uninstalled fsspec-2025.2.0\n",
      "Successfully installed appdirs-1.4.4 beautifulsoup4-4.13.3 datasets-3.3.0 deepeval-2.3.7 deprecated-1.2.18 dill-0.3.8 dirtyjson-1.0.8 diskcache-5.6.3 docx2txt-0.8 execnet-2.1.1 filetype-1.2.0 fsspec-2024.12.0 googleapis-common-protos-1.67.0 greenlet-3.1.1 grpcio-1.67.1 importlib-metadata-8.5.0 iniconfig-2.0.0 joblib-1.4.2 llama-cloud-0.1.12 llama-cloud-services-0.6.1 llama-index-0.12.17 llama-index-agent-openai-0.4.5 llama-index-cli-0.4.0 llama-index-core-0.12.17 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.4 llama-index-llms-openai-0.3.19 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.5 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.1 multiprocess-0.70.16 nltk-3.9.1 opentelemetry-api-1.30.0 opentelemetry-exporter-otlp-proto-common-1.30.0 opentelemetry-exporter-otlp-proto-grpc-1.30.0 opentelemetry-proto-1.30.0 opentelemetry-sdk-1.30.0 opentelemetry-semantic-conventions-0.51b0 pluggy-1.5.0 portalocker-3.1.1 pyarrow-19.0.0 pypdf-5.3.0 pytest-8.3.4 pytest-repeat-0.9.3 pytest-xdist-3.6.1 ragas-0.2.13 sentry-sdk-2.21.0 soupsieve-2.6 striprtf-0.0.26 tabulate-0.9.0 xxhash-3.5.0 zipp-3.21.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy deepeval ragas datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'EntityMatchMetric' from 'deepeval.metrics' (/Users/lilianahotsko/Desktop/University/Bachelors/LLMAnonymization/.venv/lib/python3.12/site-packages/deepeval/metrics/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m minibatch\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdeepeval\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m evaluate\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdeepeval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EntityMatchMetric\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m contextual_recall, contextual_precision\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'EntityMatchMetric' from 'deepeval.metrics' (/Users/lilianahotsko/Desktop/University/Bachelors/LLMAnonymization/.venv/lib/python3.12/site-packages/deepeval/metrics/__init__.py)"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "from spacy.util import minibatch\n",
    "from deepeval import evaluate\n",
    "# from deepeval.metrics import EntityMatchMetric\n",
    "# from ragas.metrics import contextual_recall, contextual_precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = [\n",
    "    (\"Apple is looking at buying U.K. startup for $1 billion\", \n",
    "     {\"entities\": [(0, 5, \"ORG\"), (27, 31, \"GPE\"), (44, 54, \"MONEY\")]}),\n",
    "    \n",
    "    (\"San Francisco considers banning sidewalk delivery robots\", \n",
    "     {\"entities\": [(0, 13, \"GPE\")]}),\n",
    "    \n",
    "    (\"Tesla plans to open a new factory in Berlin\", \n",
    "     {\"entities\": [(0, 5, \"ORG\"), (40, 46, \"GPE\")]}),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lilianahotsko/Desktop/University/Bachelors/LLMAnonymization/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "if \"ner\" not in nlp.pipe_names:\n",
    "    ner = nlp.add_pipe(\"ner\")\n",
    "else:\n",
    "    ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "for _, annotations in TRAIN_DATA:\n",
    "    for ent in annotations.get(\"entities\"):\n",
    "        ner.add_label(ent[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses at epoch 0: {'ner': np.float32(24.125904)}\n",
      "Losses at epoch 1: {'ner': np.float32(22.827713)}\n",
      "Losses at epoch 2: {'ner': np.float32(20.997963)}\n",
      "Losses at epoch 3: {'ner': np.float32(19.301352)}\n",
      "Losses at epoch 4: {'ner': np.float32(15.878076)}\n",
      "Losses at epoch 5: {'ner': np.float32(13.380622)}\n",
      "Losses at epoch 6: {'ner': np.float32(11.051787)}\n",
      "Losses at epoch 7: {'ner': np.float32(9.414019)}\n",
      "Losses at epoch 8: {'ner': np.float32(8.062301)}\n",
      "Losses at epoch 9: {'ner': np.float32(8.41878)}\n",
      "Losses at epoch 10: {'ner': np.float32(7.807492)}\n",
      "Losses at epoch 11: {'ner': np.float32(8.694886)}\n",
      "Losses at epoch 12: {'ner': np.float32(8.147778)}\n",
      "Losses at epoch 13: {'ner': np.float32(8.373519)}\n",
      "Losses at epoch 14: {'ner': np.float32(8.040446)}\n",
      "Losses at epoch 15: {'ner': np.float32(7.674814)}\n",
      "Losses at epoch 16: {'ner': np.float32(7.6837277)}\n",
      "Losses at epoch 17: {'ner': np.float32(7.0076714)}\n",
      "Losses at epoch 18: {'ner': np.float32(6.6474457)}\n",
      "Losses at epoch 19: {'ner': np.float32(7.045026)}\n",
      "Losses at epoch 20: {'ner': np.float32(5.9351583)}\n",
      "Losses at epoch 21: {'ner': np.float32(5.303683)}\n",
      "Losses at epoch 22: {'ner': np.float32(5.6122065)}\n",
      "Losses at epoch 23: {'ner': np.float32(4.8862176)}\n",
      "Losses at epoch 24: {'ner': np.float32(4.759221)}\n"
     ]
    }
   ],
   "source": [
    "with nlp.disable_pipes(*other_pipes):\n",
    "    optimizer = nlp.begin_training()\n",
    "\n",
    "    for epoch in range(25): \n",
    "        losses = {}\n",
    "        for batch in minibatch(TRAIN_DATA, size=2):\n",
    "            examples = []\n",
    "            for text, annotations in batch:\n",
    "                example = Example.from_dict(nlp.make_doc(text), annotations)\n",
    "                examples.append(example)\n",
    "            nlp.update(examples, drop=0.5, losses=losses)\n",
    "        print(f\"Losses at epoch {epoch}: {losses}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.to_disk(\"custom_ner_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_test = spacy.load(\"custom_ner_model\")\n",
    "\n",
    "EVAL_DATA = [\n",
    "    {\"text\": \"Apple is planning to acquire a startup in London\", \n",
    "     \"expected\": [(\"Apple\", \"ORG\"), (\"London\", \"GPE\")]},\n",
    "    \n",
    "    {\"text\": \"Microsoft invested $10 million in OpenAI\", \n",
    "     \"expected\": [(\"Microsoft\", \"ORG\"), (\"$10 million\", \"MONEY\"), (\"OpenAI\", \"ORG\")]},\n",
    "    \n",
    "    {\"text\": \"Elon Musk announced a new Tesla factory in Germany\", \n",
    "     \"expected\": [(\"Elon Musk\", \"PERSON\"), (\"Tesla\", \"ORG\"), (\"Germany\", \"GPE\")]}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for example in EVAL_DATA:\n",
    "    doc = nlp_test(example[\"text\"])\n",
    "    predicted_entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    \n",
    "    metric = EntityMatchMetric()\n",
    "    score = metric.evaluate(predicted_entities, example[\"expected\"])\n",
    "    \n",
    "    results.append({\"text\": example[\"text\"], \"deepeval_score\": score})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (2.2.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-macosx_12_0_arm64.whl (11.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.1-cp312-cp312-macosx_14_0_arm64.whl (24.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.6.1 scipy-1.15.1 threadpoolctl-3.5.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "from spacy.util import minibatch\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- NER Evaluation Metrics ---\n",
      "Precision: 1.0000\n",
      "Recall: 0.1250\n",
      "F1-score: 0.2222\n"
     ]
    }
   ],
   "source": [
    "# --- Step 3: Load Model and Prepare Evaluation Data ---\n",
    "nlp_test = spacy.load(\"custom_ner_model\")\n",
    "\n",
    "EVAL_DATA = [\n",
    "    {\"text\": \"Apple is planning to acquire a startup in London\", \n",
    "     \"expected\": [(\"Apple\", \"ORG\"), (\"London\", \"GPE\")]},\n",
    "    \n",
    "    {\"text\": \"Microsoft invested $10 million in OpenAI\", \n",
    "     \"expected\": [(\"Microsoft\", \"ORG\"), (\"$10 million\", \"MONEY\"), (\"OpenAI\", \"ORG\")]},\n",
    "    \n",
    "    {\"text\": \"Elon Musk announced a new Tesla factory in Germany\", \n",
    "     \"expected\": [(\"Elon Musk\", \"PERSON\"), (\"Tesla\", \"ORG\"), (\"Germany\", \"GPE\")]}\n",
    "]\n",
    "\n",
    "# --- Step 4: Compute Precision, Recall, and F1-score ---\n",
    "def evaluate_ner(nlp_model, eval_data):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for example in eval_data:\n",
    "        doc = nlp_model(example[\"text\"])\n",
    "        predicted_entities = {(ent.text, ent.label_) for ent in doc.ents}\n",
    "        expected_entities = set(example[\"expected\"])\n",
    "\n",
    "        for entity in expected_entities:\n",
    "            y_true.append(1 if entity in expected_entities else 0)\n",
    "            y_pred.append(1 if entity in predicted_entities else 0)\n",
    "\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "precision, recall, f1 = evaluate_ner(nlp_test, EVAL_DATA)\n",
    "\n",
    "print(\"\\n--- NER Evaluation Metrics ---\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 5: Evaluate with Ragas ---\n",
    "ground_truths = [ex[\"expected\"] for ex in EVAL_DATA]\n",
    "predictions = [[(ent.text, ent.label_) for ent in nlp_test(ex[\"text\"]).ents] for ex in EVAL_DATA]\n",
    "\n",
    "precision_score = contextual_precision(predictions, ground_truths)\n",
    "recall_score = contextual_recall(predictions, ground_truths)\n",
    "\n",
    "print(\"\\n--- Ragas Metrics ---\")\n",
    "print(f\"Contextual Precision: {precision_score}\")\n",
    "print(f\"Contextual Recall: {recall_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opik\n",
      "  Downloading opik-1.4.16-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting boto3-stubs>=1.34.110 (from boto3-stubs[bedrock-runtime]>=1.34.110->opik)\n",
      "  Downloading boto3_stubs-1.36.21-py3-none-any.whl.metadata (148 kB)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.12/site-packages (from opik) (8.1.8)\n",
      "Requirement already satisfied: httpx in ./.venv/lib/python3.12/site-packages (from opik) (0.28.1)\n",
      "Collecting levenshtein<1.0.0 (from opik)\n",
      "  Downloading levenshtein-0.26.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.2 kB)\n",
      "Collecting litellm (from opik)\n",
      "  Downloading litellm-1.61.6-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: openai<2.0.0 in ./.venv/lib/python3.12/site-packages (from opik) (1.61.1)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.0.0 in ./.venv/lib/python3.12/site-packages (from opik) (2.7.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in ./.venv/lib/python3.12/site-packages (from opik) (2.10.6)\n",
      "Requirement already satisfied: pytest in ./.venv/lib/python3.12/site-packages (from opik) (8.3.4)\n",
      "Requirement already satisfied: rich in ./.venv/lib/python3.12/site-packages (from opik) (13.9.4)\n",
      "Requirement already satisfied: sentry_sdk>=2.0.0 in ./.venv/lib/python3.12/site-packages (from opik) (2.21.0)\n",
      "Requirement already satisfied: tenacity in ./.venv/lib/python3.12/site-packages (from opik) (9.0.0)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from opik) (4.67.1)\n",
      "Collecting uuid6 (from opik)\n",
      "  Downloading uuid6-2024.7.10-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting botocore-stubs (from boto3-stubs>=1.34.110->boto3-stubs[bedrock-runtime]>=1.34.110->opik)\n",
      "  Downloading botocore_stubs-1.36.21-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting types-s3transfer (from boto3-stubs>=1.34.110->boto3-stubs[bedrock-runtime]>=1.34.110->opik)\n",
      "  Downloading types_s3transfer-0.11.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting mypy-boto3-bedrock-runtime<1.37.0,>=1.36.0 (from boto3-stubs[bedrock-runtime]>=1.34.110->opik)\n",
      "  Downloading mypy_boto3_bedrock_runtime-1.36.2-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting rapidfuzz<4.0.0,>=3.9.0 (from levenshtein<1.0.0->opik)\n",
      "  Downloading rapidfuzz-3.12.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.12/site-packages (from openai<2.0.0->opik) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.12/site-packages (from openai<2.0.0->opik) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from openai<2.0.0->opik) (0.8.2)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from openai<2.0.0->opik) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./.venv/lib/python3.12/site-packages (from openai<2.0.0->opik) (4.12.2)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx->opik) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx->opik) (1.0.7)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.12/site-packages (from httpx->opik) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx->opik) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->opik) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->opik) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./.venv/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.0.0->opik) (1.0.1)\n",
      "Requirement already satisfied: urllib3>=1.26.11 in ./.venv/lib/python3.12/site-packages (from sentry_sdk>=2.0.0->opik) (2.3.0)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.12/site-packages (from litellm->opik) (3.11.12)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in ./.venv/lib/python3.12/site-packages (from litellm->opik) (8.5.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in ./.venv/lib/python3.12/site-packages (from litellm->opik) (3.1.5)\n",
      "Collecting jsonschema<5.0.0,>=4.22.0 (from litellm->opik)\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in ./.venv/lib/python3.12/site-packages (from litellm->opik) (0.8.0)\n",
      "Requirement already satisfied: tokenizers in ./.venv/lib/python3.12/site-packages (from litellm->opik) (0.21.0)\n",
      "Requirement already satisfied: iniconfig in ./.venv/lib/python3.12/site-packages (from pytest->opik) (2.0.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.12/site-packages (from pytest->opik) (24.2)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in ./.venv/lib/python3.12/site-packages (from pytest->opik) (1.5.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.12/site-packages (from rich->opik) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from rich->opik) (2.19.1)\n",
      "Requirement already satisfied: zipp>=3.20 in ./.venv/lib/python3.12/site-packages (from importlib-metadata>=6.8.0->litellm->opik) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2<4.0.0,>=3.1.2->litellm->opik) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./.venv/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm->opik) (25.1.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema<5.0.0,>=4.22.0->litellm->opik)\n",
      "  Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema<5.0.0,>=4.22.0->litellm->opik)\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema<5.0.0,>=4.22.0->litellm->opik)\n",
      "  Using cached rpds_py-0.22.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->opik) (0.1.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.12/site-packages (from tiktoken>=0.7.0->litellm->opik) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./.venv/lib/python3.12/site-packages (from tiktoken>=0.7.0->litellm->opik) (2.32.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->litellm->opik) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.12/site-packages (from aiohttp->litellm->opik) (1.3.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp->litellm->opik) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp->litellm->opik) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->litellm->opik) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->litellm->opik) (1.18.3)\n",
      "Collecting types-awscrt (from botocore-stubs->boto3-stubs>=1.34.110->boto3-stubs[bedrock-runtime]>=1.34.110->opik)\n",
      "  Downloading types_awscrt-0.23.10-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in ./.venv/lib/python3.12/site-packages (from tokenizers->litellm->opik) (0.28.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm->opik) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm->opik) (2024.12.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm->opik) (6.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm->opik) (3.4.1)\n",
      "Downloading opik-1.4.16-py3-none-any.whl (384 kB)\n",
      "Downloading boto3_stubs-1.36.21-py3-none-any.whl (68 kB)\n",
      "Downloading levenshtein-0.26.1-cp312-cp312-macosx_11_0_arm64.whl (157 kB)\n",
      "Downloading litellm-1.61.6-py3-none-any.whl (6.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uuid6-2024.7.10-py3-none-any.whl (6.4 kB)\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Downloading mypy_boto3_bedrock_runtime-1.36.2-py3-none-any.whl (30 kB)\n",
      "Downloading rapidfuzz-3.12.1-cp312-cp312-macosx_11_0_arm64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading botocore_stubs-1.36.21-py3-none-any.whl (64 kB)\n",
      "Downloading types_s3transfer-0.11.2-py3-none-any.whl (19 kB)\n",
      "Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Using cached rpds_py-0.22.3-cp312-cp312-macosx_11_0_arm64.whl (342 kB)\n",
      "Downloading types_awscrt-0.23.10-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: uuid6, types-s3transfer, types-awscrt, rpds-py, rapidfuzz, mypy-boto3-bedrock-runtime, referencing, levenshtein, botocore-stubs, jsonschema-specifications, boto3-stubs, jsonschema, litellm, opik\n",
      "Successfully installed boto3-stubs-1.36.21 botocore-stubs-1.36.21 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 levenshtein-0.26.1 litellm-1.61.6 mypy-boto3-bedrock-runtime-1.36.2 opik-1.4.16 rapidfuzz-3.12.1 referencing-0.36.2 rpds-py-0.22.3 types-awscrt-0.23.10 types-s3transfer-0.11.2 uuid6-2024.7.10\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OPIK: Started logging traces to the \"Default Project\" project at https://www.comet.com/opik/naniiigock/redirect/projects?name=Default%20Project.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am just a virtual assistant, so I do not have feelings or emotions. How can I assist you today with your interests or any specific information you are looking for?\n"
     ]
    }
   ],
   "source": [
    "import os, openai\n",
    "from opik import track\n",
    "\n",
    "os.environ[\"OPIK_API_KEY\"] = \"6ZdPx21vK23sxyOqXzxlfHPsx\" \n",
    "os.environ[\"OPIK_WORKSPACE\"] = \"naniiigock\"\n",
    "\n",
    "client = openai.OpenAI()\n",
    "\n",
    "@track\n",
    "def retrieve_context(input_text):\n",
    "    return [\n",
    "        \"What specific information are you looking for?\",\n",
    "        \"How can I assist you with your interests today?\",\n",
    "        \"Are there any topics you'd like to explore or learn more about?\",\n",
    "    ]\n",
    "\n",
    "@track\n",
    "def generate_response(input_text, context):\n",
    "    full_prompt = f'If the user asks a question that is not specific, use the context to provide a relevant response.\\nContext: {\", \".join(context)}\\nUser: {input_text}\\nAI:'\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\", messages=[{\"role\": \"user\", \"content\": full_prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "context = retrieve_context(\"Hi how are you?\")\n",
    "print(generate_response(\"Hi how are you?\", context))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 3/3 [00:02<00:00,  1.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─ Evaluation test dataset (3 samples) ─╮\n",
       "│                                       │\n",
       "│ <span style=\"font-weight: bold\">Total time:       </span> 00:00:02           │\n",
       "│ <span style=\"font-weight: bold\">Number of samples:</span> 3                  │\n",
       "│                                       │\n",
       "│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">hallucination_metric: 0.0000 (avg)</span>    │\n",
       "│                                       │\n",
       "╰───────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─ Evaluation test dataset (3 samples) ─╮\n",
       "│                                       │\n",
       "│ \u001b[1mTotal time:       \u001b[0m 00:00:02           │\n",
       "│ \u001b[1mNumber of samples:\u001b[0m 3                  │\n",
       "│                                       │\n",
       "│ \u001b[1;32mhallucination_metric: 0.0000 (avg)\u001b[0m    │\n",
       "│                                       │\n",
       "╰───────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Uploading results to Opik <span style=\"color: #808000; text-decoration-color: #808000\">...</span> \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Uploading results to Opik \u001b[33m...\u001b[0m \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">View the results <a href=\"https://www.comet.com/opik/naniiigock/experiments/019512a9-e7f0-757f-9b45-e38676519aa5/compare?experiments=%5B%22019512aa-e419-710c-a75f-917d172d451c%22%5D\" target=\"_blank\">in your Opik dashboard</a>.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "View the results \u001b]8;id=338377;https://www.comet.com/opik/naniiigock/experiments/019512a9-e7f0-757f-9b45-e38676519aa5/compare?experiments=%5B%22019512aa-e419-710c-a75f-917d172d451c%22%5D\u001b\\in your Opik dashboard\u001b]8;;\u001b\\.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import opik\n",
    "from opik.evaluation import evaluate_prompt\n",
    "from opik.evaluation.metrics import Hallucination\n",
    "\n",
    "os.environ[\"OPIK_API_KEY\"] = \"6ZdPx21vK23sxyOqXzxlfHPsx\" \n",
    "os.environ[\"OPIK_WORKSPACE\"] = \"naniiigock\"\n",
    "\n",
    "# Create a dataset that contains the samples you want to evaluate\n",
    "opik_client = opik.Opik()\n",
    "dataset = opik_client.get_or_create_dataset(\"Evaluation test dataset\")\n",
    "dataset.insert([\n",
    "    {\"input\": \"Hello, world!\", \"expected_output\": \"Bonjour, monde!\"},\n",
    "    {\"input\": \"What is the capital of France?\", \"expected_output\": \"Paris\"},\n",
    "])\n",
    "\n",
    "# Run the evaluation\n",
    "result = evaluate_prompt(\n",
    "    dataset=dataset,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Translate the following text to French: {{input}}\"}],\n",
    "    model=\"gpt-3.5-turbo\",  # or your preferred model\n",
    "    scoring_metrics=[Hallucination()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maria -> GPE\n",
      "Toronto -> GPE\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from pathlib import Path\n",
    "from spacy.util import load_model_from_path\n",
    "\n",
    "model_path = Path(\"spacy/output/model-last\")\n",
    "nlp = load_model_from_path(model_path)\n",
    "\n",
    "doc = nlp(\"test message\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text} -> {ent.label_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
